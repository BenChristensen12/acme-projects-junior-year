{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Ben Christensen\n",
    "    Math 321\n",
    "    October 25, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a k-d tree to solve the Nearest Neighbor problem and use this solution to identify images of numbers used in postal service data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"/Users/benchristensen/Desktop/ACME Python Labs/Volume2-Student-Materials/Trees\")\n",
    "from trees import BSTNode, BST\n",
    "import numpy as np\n",
    "from scipy import linalg as la\n",
    "import pdb\n",
    "from scipy.spatial import KDTree\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Problem 1\n",
    "def metric(x, y):\n",
    "    \"\"\"Return the Euclidean distance between the 1-D arrays 'x' and 'y'.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if 'x' and 'y' have different lengths.\n",
    "\n",
    "    Example:\n",
    "        >>> metric([1,2],[2,2])\n",
    "        1.0\n",
    "        >>> metric([1,2,1],[2,2])\n",
    "        ValueError: Incompatible dimensions.\n",
    "    \"\"\"\n",
    "    if np.shape(x) != np.shape(y):\n",
    "        raise ValueError(\"Incompatible dimensions.\")\n",
    "    return la.norm(x-y)\n",
    "\n",
    "\n",
    "# Problem 2\n",
    "def exhaustive_search(data_set, target):\n",
    "    \"\"\"Solve the nearest neighbor search problem exhaustively. Check the distances between 'target' and each point in 'data_set'. Use the Euclidean metric to calculate distances.\n",
    "\n",
    "    Parameters:\n",
    "        data_set ((m,k) ndarray): An array of m k-dimensional points.\n",
    "        target ((k,) ndarray): A k-dimensional point to compare to 'dataset'.\n",
    "\n",
    "    Returns:\n",
    "        ((k,) ndarray) the member of 'data_set' that is nearest to 'target'.\n",
    "        (float) The distance from the nearest neighbor to 'target'.\n",
    "    \"\"\"\n",
    "    distance = la.norm(data_set[0,:] - target)\n",
    "    nearest = data_set[0, :]\n",
    "    for i in range(np.shape(data_set)[0]):\n",
    "        if la.norm(data_set[i, :] - target) < distance:\n",
    "            nearest = data_set[i, :]\n",
    "            distance = la.norm(data_set[i, :] - target)\n",
    "    return nearest, distance\n",
    "\n",
    "\n",
    "# Problem 3: Write a KDTNode class.\n",
    "class KDTNode(BSTNode):\n",
    "    \"\"\"A Node class for K-Dimension Trees. Contains vector-form data, axis value,\n",
    "    a reference to the parent node, and references to two child nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        \"\"\"Construct a new node and set the data attribute. If the\n",
    "        input data is not an ndarray, raise a typeerror.\n",
    "        \"\"\"\n",
    "        BSTNode.__init__(self, data)\n",
    "        if type(data) is not np.ndarray:\n",
    "            raise TypeError(\"KDT Nodes can only hold numpy arrays.\")\n",
    "        self.axis = None\n",
    "\n",
    "\n",
    "# Problem 4: Finish implementing this class by overriding\n",
    "#            the __init__(), insert(), and remove() methods.\n",
    "class KDT(BST):\n",
    "    \"\"\"A k-dimensional binary search tree object. Used to solve the nearest neighbor problem efficiently.\n",
    "\n",
    "    Attributes:\n",
    "        root (KDTNode): The root node of the tree. Like all other nodes in the\n",
    "            tree, the root houses data as a NumPy array.\n",
    "        k (int): The dimension of the tree (the 'k' of the k-d tree).\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the dimension attribute.\"\"\"\n",
    "        BST.__init__(self)\n",
    "        self.dimension = 0\n",
    "\n",
    "\n",
    "    def find(self, data):\n",
    "        \"\"\"Return the node containing 'data'. If there is no such node in the tree, or if the tree is empty, raise a ValueError.\n",
    "        \"\"\"\n",
    "\n",
    "        # Define a recursive function to traverse the tree.\n",
    "        def _step(current):\n",
    "            \"\"\"Recursively step through the tree until the node containing 'data' is found. If there is no such node, raise a Value Error.\n",
    "            \"\"\"\n",
    "            if current is None:                     # Base case 1: dead end.\n",
    "                raise ValueError(str(data) + \" is not in the tree\")\n",
    "            elif np.allclose(data, current.value):\n",
    "                return current                      # Base case 2: data found!\n",
    "            elif data[current.axis] < current.value[current.axis]:\n",
    "                return _step(current.left)          # Recursively search left.\n",
    "            else:\n",
    "                return _step(current.right)         # Recursively search right.\n",
    "\n",
    "        # Start the recursion on the root of the tree.\n",
    "        return _step(self.root)\n",
    "\n",
    "    def insert(self, data):\n",
    "        \"\"\"Insert a new node containing 'data' at the appropriate location.\n",
    "        Return the new node. This method should be similar to BST.insert().\n",
    "        \"\"\"\n",
    "        def _step(current):\n",
    "            #Check if the node is already in the tree\n",
    "            if np.allclose(data, current.value):\n",
    "                raise ValueError(str(data) + \" is already in the tree\")\n",
    "            #If at a leaf, insert to the appropriate side\n",
    "            elif data[current.axis] < current.value[current.axis]:\n",
    "                if current.left is None:\n",
    "                    current.left = KDTNode(data)\n",
    "                    current.left.prev = current\n",
    "                    if current.axis == self.dimension - 1:\n",
    "                        current.left.axis = 0\n",
    "                    else:\n",
    "                        current.left.axis = current.axis + 1\n",
    "                    return current.left\n",
    "                else:\n",
    "                    return _step(current.left)\n",
    "            elif data[current.axis] >= current.value[current.axis]:\n",
    "                if current.right is None:\n",
    "                    current.right = KDTNode(data)\n",
    "                    current.right.prev = current\n",
    "                    if current.axis == self.dimension - 1:\n",
    "                        current.right.axis = 0\n",
    "                    else:\n",
    "                        current.right.axis = current.axis + 1\n",
    "                    return current.right\n",
    "                else:\n",
    "                    return _step(current.right)\n",
    "        # Start the recursion on the root of the tree.\n",
    "        if self.root is None:\n",
    "            self.root = KDTNode(data)\n",
    "            self.root.axis = 0\n",
    "            self.dimension = len(self.root.value)\n",
    "        else:\n",
    "            return _step(self.root)\n",
    "\n",
    "    def remove(self, **kwargs):\n",
    "        \"\"\"Raise an error so they don't try to remove a node.\"\"\"\n",
    "        raise NotImplementedError(\"You are not allowed to remove\")\n",
    "\n",
    "\n",
    "# Problem 5\n",
    "def nearest_neighbor(data_set, target):\n",
    "    \"\"\"Use your KDT class to solve the nearest neighbor problem.\n",
    "\n",
    "    Parameters:\n",
    "        data_set ((m,k) ndarray): An array of m k-dimensional points.\n",
    "        target ((k,) ndarray): A k-dimensional point to compare to 'dataset'.\n",
    "\n",
    "    Returns:\n",
    "        The point in the tree that is nearest to 'target' ((k,) ndarray).\n",
    "        The distance from the nearest neighbor to 'target' (float).\n",
    "    \"\"\"\n",
    "    m,k = np.shape(data_set)\n",
    "    my_KDT = KDT()\n",
    "    for row in range(m):\n",
    "        my_KDT.insert(data_set[row, :])\n",
    "    distance = metric(my_KDT.root.value, target)\n",
    "\n",
    "\n",
    "    def KDTsearch(current, neighbor, dist):\n",
    "        \"\"\"The actual nearest neighbor search algorithm.\n",
    "\n",
    "        Parameters:\n",
    "            current (KDTNode): the node to examine.\n",
    "            neighbor (KDTNode): the current nearest neighbor.\n",
    "            distance (float): the current minimum distance.\n",
    "\n",
    "        Returns:\n",
    "            (ndarray): The new nearest neighbor in the tree.\n",
    "            (float): The new minimum distance.\n",
    "        \"\"\"\n",
    "        if current is None:\n",
    "            return neighbor, dist\n",
    "        index = current.axis\n",
    "        if metric(current.value, target) < dist:\n",
    "            neighbor = current\n",
    "            dist = metric(current.value, target)\n",
    "        if target[index] < current.value[index]:\n",
    "            neighbor, dist = KDTsearch(current.left, neighbor, dist)\n",
    "            if target[index] + dist >= current.value[index]:\n",
    "                neighbor, dist = KDTsearch(current.right, neighbor, dist)\n",
    "        else:\n",
    "            neighbor, dist = KDTsearch(current.right, neighbor, dist)\n",
    "            if target[index] - dist <= current.value[index]:\n",
    "                neighbor, dist = KDTsearch(current.left, neighbor, dist)\n",
    "        return neighbor, dist\n",
    "\n",
    "    ans1, ans2 = KDTsearch(my_KDT.root, my_KDT.root, distance)\n",
    "    return ans1.value, ans2\n",
    "\n",
    "# Problem 6\n",
    "class KNeighborsClassifier(object):\n",
    "    \"\"\"A k-nearest neighbors classifier object. Uses SciPy's KDTree to solve\n",
    "    the nearest neighbor problem efficiently.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, labels):\n",
    "        \"\"\"Initialize the training set and labels. Construct the KDTree from\n",
    "        the training data.\n",
    "\n",
    "        Parameters:\n",
    "            data (ndarray): Training data.\n",
    "            labels (ndarray): Corresponding labels for the training data.\n",
    "        \"\"\"\n",
    "        self.tree = KDTree(data)\n",
    "        self.labels = labels\n",
    "\n",
    "    def predict(self, testpoints, k):\n",
    "        \"\"\"Predict the label of a new data point by finding the k-nearest\n",
    "        neighbors.\n",
    "\n",
    "        Parameters:\n",
    "            testpoints (ndarray): New data point(s) to label.\n",
    "            k (int): Number of neighbors to find.\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        if testpoints.ndim == 1:\n",
    "            n = 1\n",
    "            testpoints = [testpoints]\n",
    "        else:\n",
    "            n = np.shape(testpoints)[1]\n",
    "        for p in range(n):\n",
    "            voting = []\n",
    "            min_distances, indicies = self.tree.query(testpoints[p], k)\n",
    "            for j in range(k):\n",
    "                voting.append(self.labels[indicies[j]])\n",
    "            predictions.append(stats.mode(voting)[0][0])\n",
    "        return np.array(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My prediction:  [1]\n",
      "Label:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "points, testpoints, labels, testlabels = np.load('/Users/benchristensen/Desktop/ACME Python Labs/Volume2-Student-Materials/NearestNeighbor/PostalData.npz').items()\n",
    "Classifieds = KNeighborsClassifier(points[1], labels[1])\n",
    "img = testpoints[1][63]\n",
    "prediction = Classifieds.predict(testpoints[1][63], 4)\n",
    "print(\"My prediction: \", prediction)\n",
    "print(\"Label: \", testlabels[1][63])\n",
    "plt.imshow(img.reshape((28, 28)), cmap=\"gray\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
